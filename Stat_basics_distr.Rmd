---
title: "Distributions"
description: |
  
author:
  - name: Tehilla Ostrovsky
    #url: 
    affiliation: LMU
    #affiliation_url: 
date: "`r Sys.Date()`"
output: distill::distill_article
---
# The Normal Distribution
Bivariate normal distribution is a statistical model that describes the joint distribution of two random variables that are normally distributed. It is used to analyze the relationship between two continuous variables, such as height and weight or income and education level. The distribution is characterized by two parameters: the mean and the covariance. 


The mean represents the center of the distribution, while the covariance measures the degree to which the two variables vary together.

A 3D simulation image of a bivariate normal distribution (see below) shows two variables plotted on the x and y-axis, with the height of the surface representing the probability density of each combination of values. 


The surface is shaped like an elliptical mound, with the peak at the mean of the distribution and the orientation of the ellipse determined by the covariance. 

The shape of the ellipse reflects the degree to which the two variables are correlated, with a more circular shape indicating low correlation and a more elongated shape indicating high correlation. 


The visualization was created as a tool to help statistics students to understand the relationship between two variables in a more intuitive way.


I created this plot to illustrate the Bivariat normal distribution in Python (here is the link to the [code]( https://colab.research.google.com/drive/1gVUhfoiwFYnisKvdE_HEgiYdiuyPZpcp) 



```{r bivar, fig.align="center", out.height="90%", out.width = "90%"}
library(knitr)
knitr::include_graphics("BIVARNORMAL.png")


```



# Central Limit Theorm 


The central limit theorem is a fundamental concept in statistics that states that as the sample size increases, the distribution of the sample means will approach a normal distribution, regardless of the underlying distribution of the population. 


This is true for any independent, identically distributed random variables with a finite mean and variance. The central limit theorem is essential because it allows us to make inferences about a population based on a sample.

The basic equation for the central limit theorem is:

$z = (x̄ - μ) / (σ / √n)$

where $z$ is the standard normal random variable, $x̄$ is the sample mean, μ is the population mean, σ is the population standard deviation, and n is the sample size.

A simulation plot of the central limit theorem can demonstrate how the sample mean distribution approaches a normal distribution as the sample size increases. The plot can show different sample sizes on the x-axis and the sample mean distribution on the y-axis. The simulation can be run using a non-normal population distribution, such as the uniform or exponential distribution, and show that as the sample size increases, the distribution of the sample means becomes increasingly normal. The plot can also illustrate how the standard deviation of the sample means decreases as the sample size increases, indicating more precise estimates of the population mean. This visualization can help to reinforce the concept of the central limit theorem and its practical implications in statistical analysis.

```{r central, fig.align="center", out.height="90%", out.width = "90%"}

knitr::include_graphics("CentralTheorm_ND_sim.png")


```


Why do we need central theorm?

Intuitively, we can think of the distribution of sample means as a way of characterizing the variability that we would expect to see in the sample means if we were to take many different samples from the same population. If we were to take multiple samples of the same size from a population and calculate the sample mean for each sample, we would end up with a range of different values. The distribution of these sample means would give us a sense of how much variability we can expect in the sample mean, which in turn provides information about the uncertainty in our estimate of the population mean.

The distribution of sample means is important because it allows us to make statements about the population mean with a certain degree of confidence. By calculating the standard error of the mean and constructing confidence intervals around the sample mean, we can estimate the range of values that the population mean is likely to fall within with a certain level of confidence. This is a powerful tool in statistical inference and is used in a wide range of fields, from medicine to finance to social sciences.
